# Hardware Advancements
### Mooreâ€™s Law
- Number of transistors roughly **doubles every ~2 years**
- Leads to:
    - Increased compute power
    - Reduced cost per computation

---
### GPUs and Specialized Hardware
- **NVIDIA** introduced **CUDA**, enabling massive parallel computation
- GPUs made large matrix multiplications feasible

---
### Specialized Accelerators
- **FPGAs** (e.g., Xilinx) for custom pipelines
- **ASICs**:
    - TPUs (Tensor Processing Units)
    - Edge TPUs for low-power devices
- **NPUs**:
    - Dedicated neural processors in smartphones

> Deep learning is only practical with parallel hardware.

---
