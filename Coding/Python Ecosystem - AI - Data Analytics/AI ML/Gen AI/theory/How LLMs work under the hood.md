# Attention is all you need (By Google)
[View paper](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)

---
# Transformer
![[transformer.excalidraw|700]]

---
# LLM
![[llm.excalidraw|700]]

---
> For any input token, it predicts the next token using the machine learning data.

---
> Hence these LLM models require GPU's.

---
