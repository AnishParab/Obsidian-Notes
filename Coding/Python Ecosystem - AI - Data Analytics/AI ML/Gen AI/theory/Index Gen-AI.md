# Core Foundations of Generative AI
[[Understanding Large Language Models (LLM)]]
[[Deep dive into GPT Architecture]]
[[How LLMs work under the hood]]
[[Fundamentals of Tokenization in NLP]]
[[Implementing a custom Tokenizer in Python - pip freeze]]

### Transformer Architecture
[[The Transformer Breakthrough - Google's Paper on Attention]]
[[Vector Embeddings]]
[[Role of Positional Encodings in Tranformers and Self Attention Mechanism]]
[[Self Attention]]
[[Multi-Head Attention Mechanism]]
[[Feed Forward - Linear - Softmax in LLM Transformer]]

---
# API Setup and Integration

---
