# Phase 2 â€“ Data Preparation

- **Definition:** Steps to explore, preprocess, and condition data before modeling and analysis.  
- Requires an **analytic sandbox**, where the team can execute, load, and transform data.  
- Tasks in this phase are **iterative** and may be performed multiple times, often **not in a predefined order**.  

---
# Key Activities
- **Data cleaning:** Handle missing values, duplicates, and inconsistencies.  
- **Data transformation:** Normalize, aggregate, or encode data for modeling.  
- **Data integration:** Combine multiple data sources for analysis.  
- **Data sampling and partitioning:** Prepare training, testing, and validation datasets.  

---
# Traditional Tools
- **Spreadsheets** (Excel, LibreOffice Calc)  
- **SQL-based tools** for structured data extraction and transformation  
- **ETL tools**: Informatica, Talend  

---
# Modern Tools
- **Big Data Platforms:** Hadoop, Apache Spark  
- **Data preparation platforms:** Alteryx, OpenRefine, Trifacta  
- **Python/R libraries:** Pandas, NumPy, dplyr, tidyr  
- **Cloud-based solutions:** AWS Glue, Google Cloud DataPrep, Azure Data Factory  

> Modern tools enable **handling large, unstructured, and semi-structured data**, whereas traditional tools are more suited for **structured, smaller datasets**.

---
